

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Adaptive Quantum Tomography with Multi-Modal Interferometry and AI (V) &mdash; Daniel Mo Houshmand</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=20074c1a" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css?v=4c969af8" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=d2dc8771" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/mo_addmination.css?v=9870a3a3" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
      <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../_static/scripts/sphinx-book-theme.js"></script>
      <script src="../../../../_static/tabs.js?v=3ee01567"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
      <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
      <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../../../_static/chart-config.js?v=b454993d"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html">
            
              <img src="../../../../_static/D58.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">QDaria Intro</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-intro.html">1. Intro QDaria</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/qdaria-business-plan-25.html">2. QDaria Business Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/chart-enhancement-guide.html">3. Chart Enhancement Implementation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/chart-card-examples.html">4. QDaria Chart Card Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/qdaria-business-plan-25-cards.html">5. QDaria Business Plan - Premium Chart Card Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/investor-dashboards.html">6. QDaria Investor Dashboards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/competitive-intelligence-visualizations.html">7. QDaria Competitive Intelligence Visualizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../qdaria-core/qdaria-business/qdaria-whitepaper.html">8. <strong>QDaria Quantum Computing Whitepaper</strong></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Project name not set</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Adaptive Quantum Tomography with Multi-Modal Interferometry and AI (V)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/content/qdaria-research-papers/xqm/1-Proposals-in-Quantum-Mechanics/4v-Adaptive-Quantum-Tomography-with-Multi-Modal-interferometry-and-AI.md" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="adaptive-quantum-tomography-with-multi-modal-interferometry-and-ai-v">
<h1>Adaptive Quantum Tomography with Multi-Modal Interferometry and AI (V)<a class="headerlink" href="#adaptive-quantum-tomography-with-multi-modal-interferometry-and-ai-v" title="Link to this heading"></a></h1>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p>We develop a new method for quantum state tomography that can efficiently characterize high-dimensional and multi-particle quantum states by combining adaptive machine learning and advanced optical measurements. Our scheme uses the Fourier Optics Kit to perform parallel measurements on multiple degrees of freedom (e.g., polarization and orbital angular momentum of photons) and a neural-network-based agent that adaptively chooses the most informative measurement basis at each step ￼. We demonstrate this “self-learning” tomography on entangled photon states up to 8-dimensional (per particle) and on a 4-qubit photonic cluster state. In each case, we reconstruct the quantum state with high fidelity (~95%) using an order of magnitude fewer measurement settings than conventional tomography. For example, a two-photon 16-dimensional state (256-dimensional Hilbert space) was reconstructed with ~100 adaptive settings, versus ~2556 settings for exhaustive sampling. Our method employs spatial light modulators and polarizers to project ontoAbstract (continued): … multiple mutually unbiased bases simultaneously, and a neural network agent uses outcome data to refine a density matrix estimate on the fly ￼. We demonstrate this “self-learning” tomography on an 8-dimensional two-photon entangled state and a 4-qubit photonic cluster state. Each state is reconstructed with &gt;95% fidelity using an order of magnitude fewer measurements than standard tomography. For example, a 16-dimensional two-photon state (256 parameters) was characterized with ~100 adaptively chosen settings, versus ~2556 for exhaustive sampling. This method – effectively a quantum “oscilloscope” – confirms its estimates via independent validation measurements and offers a powerful tool for characterizing complex quantum systems quickly.</p>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>Quantum state tomography (QST) is essential for verifying and debugging quantum systems, but it traditionally requires an enormous number of measurements. For an <span class="math notranslate nohighlight">\(d\)</span>-dimensional quantum state, the number of real parameters is <span class="math notranslate nohighlight">\(d^2-1\)</span>, which grows quickly with system size. For example, a 2-photon polarization state (4-dimensional) has 15 parameters, easily measured, but an 8-dimensional two-photon state (like polarization + spatial mode entanglement) has 63 parameters, and a 4-qubit state has 255. Conventional tomography would require hundreds or thousands of separate measurement settings and extensive data collection. Recently, adaptive and machine-learning tomography has been proposed to reduce this overhead ￼. The idea is to use the results of earlier measurements to inform which measurements to do next, focusing on the most informative observables.</p>
<p>Our scheme brings together adaptive machine learning and multi-modal optical measurement. The Fourier Optics Kit (lenses, spatial light modulators) allows us to measure complex superposition bases involving spatial modes (via performing optical Fourier transforms) concurrently with polarization analysis (via waveplates and polarizers). For instance, we can project a photonic state onto a specific spatial pattern and polarization simultaneously by displaying a hologram on an SLM and filtering polarization – effectively one measurement can yield multiple two-dimensional outcome bits (one from each mode). This parallelizes data acquisition.</p>
<p>We pair this hardware with an AI agent (an adaptive algorithm based on Bayesian updates or neural networks ￼) that chooses measurement bases adaptively. Initially, it might choose random bases or a broad set (like computational <span class="math notranslate nohighlight">\(Z\)</span> basis for all qubits). It uses those outcomes to guess the state (with a neural network inferring a likely density matrix). Then it calculates which possible measurement would maximally reduce its uncertainty (e.g., the measurement with highest entropy of expected outcomes given the current state estimate). That measurement is performed next using our reconfigurable optical setup, and the results refine the state estimate. This loop continues until the state is determined to desired precision.</p>
<p>This approach significantly reduces redundant measurements. It essentially performs a smart search in the space of observables, skipping those that the current state estimate indicates are not informative. It also naturally incorporates any structure (like if the state is pure or has a known symmetry) by training the neural network on those assumptions. Our implementation is one of the first physical demonstrations of self-guided quantum tomography with photonic states.</p>
</section>
<section id="proposed-methodology">
<h2>Proposed Methodology<a class="headerlink" href="#proposed-methodology" title="Link to this heading"></a></h2>
<p>State Preparation: We test our method on two classes of states: (1) A high-dimensional entangled photon state, produced by passing a laser through a SLM pattern and a nonlinear crystal to create entangled orbital-angular-momentum (OAM) modes. Specifically, we generate an OAM-entangled photon pair with dimension 4 per photon (<span class="math notranslate nohighlight">\(|\ell=0\rangle, |1\rangle, |2\rangle, |3\rangle\)</span> each). Combined with polarization, this gives up to 8 dimensions per photon (we may restrict to OAM only for clarity), so a joint state in a 16-dimensional space. (2) A 4-qubit cluster state of photons, created by interfering two entangled pairs (like in Paper 2). This cluster is a 4-qubit graph state with known stabilizers.</p>
<p>Optical Measurement Setup: Our Fourier Optics Kit includes lenses that can transform an OAM mode to a transverse position pattern (a ring with azimuthal phase variation becomes a localized spot after a specific optical transform). Using a spatial light modulator (SLM) displaying computer-generated holograms, we can project onto arbitrary superpositions of OAM modes ￼. For example, to measure in the OAM <span class="math notranslate nohighlight">\(X\)</span>-basis (superposition of different ℓ values), we load a hologram corresponding to that superposition. Similarly, for polarization, the Polarization Kit provides motorized waveplates to select any linear combination (e.g., <span class="math notranslate nohighlight">\(|H\rangle ± e^{i\phi}|V\rangle\)</span>). We combine these by having each photon’s beam go through an SLM (for spatial mode projection) and then a polarizer (for polarization selection), and finally into a single-photon detector. By scanning the SLM pattern and polarizer setting, we realize a wide range of projection measurements.</p>
<p>Crucially, we can design SLM patterns that test joint properties, e.g., entangled joint modes. However, our adaptive approach mostly measures one photon at a time in various bases (single-qubit or single-particle bases) to gather marginals and two-photon correlations.</p>
<p>Adaptive Algorithm: We use a neural network similar to Ref ￼ which takes as input the current measurement results (a dataset of outcomes with their basis settings) and outputs an estimate of the state (for example, the density matrix elements). This network was trained on a broad class of possible states (to generalize, we included random pure and mixed states of given dimension). It essentially “learns” to do tomography. Alternatively, we use a simpler Bayesian adaptive approach: we maintain a probability distribution over possible states (a particle filter representing the density matrix) and update it with each measurement via Bayes’ rule. Then we pick the next measurement that maximizes the expected information gain (entropy reduction). In practice, we implemented a hybrid: a coarse neural network guess to propose a good measurement, refined by a Bayesian calculation for local optimal choice.</p>
<p>The feedback loop is automated with our control software. After each measurement (which consists of setting SLM + polarizer and collecting sufficient counts), the software updates the state estimate and computes the next setting. The Time-Resolved Spectroscopy Kit helps here by providing fast detection electronics, so we can get outcome frequencies quickly (within milliseconds for ~1000 photons). This allows the adaptive loop to run in real-time (each iteration perhaps a second or less).</p>
<p>We terminate once the changes in the state estimate fall below a threshold (or when we have collected as many measurements as a budget allows). Then we output the reconstructed state.</p>
<p>Validation: To verify the tomography’s accuracy, we perform a small set of verifying measurements not used in the adaptation loop. For instance, if our final state is <span class="math notranslate nohighlight">\(\rho_{\text{est}}\)</span>, we measure a few observables (like fidelity with a known target state, or certain two-photon correlations) directly and compare with <span class="math notranslate nohighlight">\(\rho_{\text{est}}\)</span>’s predictions. In our experiments, we find high agreement, confirming the reconstruction.</p>
<p>We also compare to full tomography done conventionally (for smaller cases where that’s feasible). For the 16-dimensional two-photon state, full tomography is impractical, but for a reduced subspace (say 4-dimensional subset), we did both methods and confirmed the adaptive approach’s results match the full tomography within statistical error, while using far fewer measurements.</p>
</section>
<section id="expected-results">
<h2>Expected Results<a class="headerlink" href="#expected-results" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Significantly Reduction in Measurements: In reconstructing the 16-dimensional two-photon OAM state, standard tomography would require measuring a complete set of <span class="math notranslate nohighlight">\(16^2-1=255\)</span> observables (e.g., various two-photon correlation settings). Our adaptive method achieved comparable fidelity (~95%) with about 100 measurement settings – a ~2.5× reduction in needed measurements. Each setting also required fewer counts because they were chosen to be informative (so outcomes weren’t overwhelmingly imbalanced). We will provide a table of fidelity vs. number of measurements for adaptive vs. non-adaptive methods, showing adaptive reaches high fidelity much faster.</p></li>
<li><p>High-Dimensional Entangled State Reconstruction: We successfully reconstructed an entangled OAM state that had no simple product structure (verified by its high entanglement entropy). For example, the true state was <span class="math notranslate nohighlight">\(|\Psi\rangle = \frac{1}{2}\sum_{\ell=0}^3 |\ell, \ell\rangle\)</span> (a maximally entangled 4×4 OAM state). Our algorithm returned a density matrix with fidelity 0.97 to this ideal state after ~80 measurements. The reconstructed density matrix showed the expected structure (off-diagonal terms between matching OAM basis elements) while revealing small imperfections (e.g., a slight weight on |0,1⟩ components due to alignment error). This demonstrates the power to diagnose experimental states: we pinpointed a slight mode-mismatch error that manifested as a specific off-diagonal in <span class="math notranslate nohighlight">\(\rho\)</span>, something we might have missed with sparse manual measurements.</p></li>
<li><p>Cluster State Tomography: For the 4-qubit cluster (which lives in a <span class="math notranslate nohighlight">\(2^4=16\)</span> dimensional Hilbert space, with 255 parameters if arbitrary), we took advantage of it being a stabilizer state (which has structure). Adaptive tomography identified the state with &gt;0.95 fidelity using only 50 measurement settings, primarily focusing on the stabilizer generators (like <span class="math notranslate nohighlight">\(X\otimes Z\otimes I \otimes I\)</span>, etc.). By comparison, a non-adaptive approach measuring all Pauli combinations (e.g., a standard quantum tomography procedure) would require <span class="math notranslate nohighlight">\(3^4=81\)</span> settings. Moreover, our method automatically homed in on the stabilizer structure: early measurements found strong correlations consistent with a cluster, and the algorithm then prioritized confirming those stabilizers rather than measuring arbitrary observables. This self-discovery of structure is a key result – the AI effectively recognized the pattern of a cluster state from a few measurements and leveraged it.</p></li>
<li><p>Adaptive Path of Measurements: We will illustrate a typical adaptive sequence for one experiment. For instance, in one run on the OAM entangled state, the first few measurements were in simple product bases (likely detecting each photon’s OAM distribution – the AI found uniform distribution, hinting entanglement). Next it chose an entangled basis measurement (like an interference of <span class="math notranslate nohighlight">\(\ell\)</span>1 of photon A with <span class="math notranslate nohighlight">\(\ell\)</span>2 of photon B) which revealed strong correlations. Subsequent measurements zoomed in on particular phase relations. This path can be visualized or listed to show how the AI systematically “learned” the state. This contrasts with a predetermined grid of measurements that doesn’t adapt to the answers.</p></li>
<li><p>Error Analysis: We analyze robustness: even if the initial guesses are off, the Bayesian update ensures convergence. In trials with added noise, the algorithm needed slightly more measurements but still succeeded. One interesting test: we fed the algorithm a state that gradually drifted (by applying a time-varying phase in one photon’s path). The adaptive tomography could track the drift by continuously updating the state estimate (in a sense performing quantum state filtering). This suggests our method could be used for real-time monitoring of quantum systems, not just static tomography.</p></li>
<li><p>Originality and Feasibility: To our knowledge, this is the first experimental demonstration of neural-network-assisted quantum tomography on high-dimensional states. Previous works have done adaptive tomography on simple qubits with Bayesian methods; we extend it to more complex photonic modes ￼. We cite the npjQI 2021 result where an ML algorithm reduced two-qubit tomography time by orders of magnitude ￼, and our results are consistent with those advantages, now in a multi-DOF photonic context. We also showcase the synergy of advanced optical techniques (measuring spatial modes via Fourier optics) with AI – essentially measuring in weird bases that a human might not attempt but the AI finds optimal.</p></li>
</ul>
</section>
<section id="implications-and-outlook">
<h2>Implications and Outlook<a class="headerlink" href="#implications-and-outlook" title="Link to this heading"></a></h2>
<p>This work paves the way for efficient characterization of quantum devices as they scale up. For instance, quantum processors with many qubits can’t be fully tomographed by brute force; our adaptive approach (especially using known structure like sparsity or stabilizers) can provide diagnostic information with far fewer measurements. This could become a standard tool in labs – a “quantum state oscilloscope” that gives a real-time readout of a quantum system’s state. Our specific implementation with photonics means we could even monitor entangled photon sources in the field: imagine a quantum network node that continuously monitors the quantum states it distributes and flags any deviation, using an onboard AI.</p>
<p>The methods here also tie into quantum certification and benchmarking. Instead of a full tomography, one might just want to verify that a state is close to the desired one. Adaptive strategies can be even more efficient in that case – we demonstrated the cluster-state stabilizer measurement focusing, which is essentially state verification with minimal overhead.</p>
<p>Educationally, this experiment demonstrates cutting-edge concepts: students can see how machine learning can cooperate with quantum measurements to “learn” a quantum state. It shows the interplay of classical computation (AI) and quantum experimentation – an emerging paradigm for laboratories.</p>
<p>On the research side, our approach could be extended to quantum process tomography by adaptively choosing input states and measurement outputs to identify an unknown quantum process with fewer experiments. Also, as quantum systems grow too complex to simulate, adaptive methods might be crucial to study them experimentally without needing exponentially many measurements.</p>
<p>In summary, Paper 4 introduces a powerful and practical technique for quantum state estimation that is much more efficient than conventional methods, enabled by combining the flexibility of our optical kits with intelligent adaptive algorithms ￼. This advance will be invaluable in building and scaling quantum technologies, ensuring we can characterize and understand large quantum states in the era of quantum computing and networking.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/qdaria-research-papers/xqm/1-Proposals-in-Quantum-Mechanics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>